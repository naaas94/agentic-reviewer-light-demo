**LLM-powered semantic auditing â€” no API keys, runs locally, free.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Input: "Delete my data permanently"                        â”‚
â”‚  Predicted: Access Request (85% confidence)                 â”‚
â”‚                          â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ğŸ¤– Local LLM Analysis (via Ollama)                  â”‚   â”‚
â”‚  â”‚  â€¢ Evaluate prediction accuracy                      â”‚   â”‚
â”‚  â”‚  â€¢ Suggest corrections                               â”‚   â”‚
â”‚  â”‚  â€¢ Generate explanations                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â†“                                  â”‚
â”‚  Verdict: âŒ Incorrect                                      â”‚
â”‚  Suggested: Erasure                                         â”‚
â”‚  Reason: "Text requests deletion, not data access"         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Quick Start (3 steps)

### 1. Install Ollama (free, local LLM runtime)

Download from **[ollama.ai/download](https://ollama.ai/download)** â€” works on Mac, Windows, Linux.

Then start it:
```bash
ollama serve
```

### 2. Clone & Install

```bash
git clone https://github.com/YOUR_USERNAME/agentic-reviewer-demo.git
cd agentic-reviewer-demo
pip install -r requirements.txt
```

### 3. Run

```bash
python run_demo.py
```

**The script auto-downloads the LLM model on first run.** No API keys. No cloud. Everything local.

Check `outputs/` for generated artifacts.

---

## What It Does

1. **Generates** synthetic GDPR/CCPA data subject requests
2. **Reviews** each prediction using LLM semantic analysis
3. **Corrects** misclassifications with reasoning
4. **Produces** traceable artifacts (CSV, JSON, Markdown report)

---

## Output Artifacts

```
outputs/2024_12_04_153000/
â”œâ”€â”€ 00_config.json          # Run configuration (reproducibility)
â”œâ”€â”€ 01_synthetic_data.csv   # Generated classification samples
â”œâ”€â”€ 02_review_results.json  # Full LLM responses
â”œâ”€â”€ 03_labeled_dataset.csv  # Corrected labels with reasoning
â”œâ”€â”€ 04_report.md            # Analysis report
â””â”€â”€ 05_metrics.json         # Accuracy statistics
```

---

## Terminal Output

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    AGENTIC REVIEWER DEMO                     â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Run ID: 2024_12_04_153000                                    â•‘
â•‘ Samples: 15 | Seed: 42 | LLM: On                             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ PHASE 1: Generate Synthetic Data       âœ“ 15 samples          â•‘
â•‘ PHASE 2: LLM Review                    âœ“ 15/15 reviews       â•‘
â•‘ PHASE 3: Generate Report               âœ“ 450 words           â•‘
â•‘ PHASE 4: Save Artifacts                âœ“ 5 files             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ RESULTS                                                      â•‘
â•‘ â”œâ”€ Correct:    10 (66.7%)                                   â•‘
â•‘ â”œâ”€ Incorrect:   4 (26.7%) â†’ corrections suggested           â•‘
â•‘ â””â”€ Uncertain:   1 (6.6%)                                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## Demo Options

```bash
# Standard demo (12 samples)
python run_demo.py

# More samples
python run_demo.py --samples 25

# Reproducible run
python run_demo.py --seed 42

# Quick preview without LLM (for CI/testing)
python run_demo.py --mock
```

### Why Ollama?

| Feature | Ollama | Cloud APIs |
|---------|--------|------------|
| **Cost** | Free | Pay per token |
| **API Keys** | None needed | Required |
| **Privacy** | Data stays local | Sent to cloud |
| **Setup** | 1 download | Account signup |
| **Works offline** | Yes | No |

---

## What This Demonstrates

| Skill | Evidence |
|-------|----------|
| **LLM Integration** | Ollama orchestration, prompt engineering |
| **Data Engineering** | Synthetic generation, schema validation |
| **MLOps Patterns** | Reproducibility, artifact management |
| **Code Quality** | Clean architecture, type hints, error handling |

---

## Project Structure

```
agentic-reviewer-demo/
â”œâ”€â”€ run_demo.py              # Single entry point
â”œâ”€â”€ requirements.txt         # Minimal dependencies
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ synthetic_generator.py  # Data generation with configurable confusion
â”‚   â”œâ”€â”€ review_engine.py        # LLM review with caching & parallelism
â”‚   â””â”€â”€ report_generator.py     # Markdown report generation
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ labels.yaml          # GDPR/CCPA label definitions
â”œâ”€â”€ tests/                   # Pytest test suite
â”‚   â”œâ”€â”€ test_synthetic_generator.py
â”‚   â”œâ”€â”€ test_review_engine.py
â”‚   â””â”€â”€ test_report_generator.py
â”œâ”€â”€ .github/workflows/       # CI configuration
â”‚   â””â”€â”€ ci.yml
â””â”€â”€ outputs/                 # Generated runs
```

---

## Testing

Run the test suite:

```bash
# Install test dependencies
pip install pytest pytest-cov pytest-asyncio

# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ -v --cov=core --cov-report=term-missing
```

---

## Architecture Highlights

| Feature | Implementation |
|---------|---------------|
| **Prompt Caching** | MD5 hash-based cache avoids redundant LLM calls |
| **Parallel Execution** | `asyncio.gather()` + semaphore for concurrent reviews |
| **Retry with Backoff** | Exponential backoff for Ollama resilience |
| **Configurable Confusion** | Static patterns or dynamic semantic similarity |

---

## Production Version

This is a **minimal demo** for quick validation. For the full production implementation with:

- ğŸ”’ Security layer (prompt injection detection)
- âš¡ LRU caching + circuit breaker
- ğŸŒ FastAPI REST interface
- ğŸ“Š System monitoring & health checks
- ğŸ“ SQLite audit logging

See: **[agentic-reviewer](https://github.com/naaas94/agentic-reviewer)**

---

## License

MIT

---

*Built to demonstrate LLM-powered classification auditing.*

